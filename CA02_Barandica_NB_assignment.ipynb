{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Computer Assignment 02: Naive Bayes**\n",
        "\n"
      ],
      "metadata": {
        "id": "MHM6v3qM29fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkovyFio4c1F",
        "outputId": "bbc0a5d8-a6c3-42f7-88e9-830a64c33b78"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the needed packages for this code\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import zipfile\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "oPUd2N8_Lc-A"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is a Python function named \"make_Dictionary\" that takes the root directory as input and creates a dictionary of the 3000 most common words in the emails stored in the directory. \n"
      ],
      "metadata": {
        "id": "DwFWw4ucdlrc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "id": "jjKF0nIMwz8_",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def make_Dictionary(root_dir):\n",
        "  all_words = [] #This first steps creates an empty list to store the words extracted\n",
        "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] #creates \"emails\" list\n",
        "  for mail in emails:\n",
        "    with open(mail) as m: \n",
        "      for line in m:\n",
        "        words = line.split() #splits current line into words\n",
        "        all_words += words\n",
        "  dictionary = Counter(all_words) #creates \"dictionary\" with count of each word\n",
        "  list_to_remove = list(dictionary)\n",
        "\n",
        "  for item in list_to_remove:\n",
        "    if item.isalpha() == False: #checks if alphabetic or not, returns True if items are alphabetic\n",
        "      del dictionary[item] #removes item from \"dictionary\" if not alphabetical\n",
        "    elif len(item) == 1:\n",
        "      del dictionary[item] #removes single character and stop words\n",
        "  dictionary = dictionary.most_common(3000) #returns the most 3000 most common words\n",
        "  return dictionary \n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next function first returns \"features matrix\" and \"train labels\" and uses them to open and close files to make sure all words are added and counted in the dictionary properly. Then, the file path is split in order to identify spam vs real emails using specific naming. \n",
        "\n"
      ],
      "metadata": {
        "id": "r99mtV62nCjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "dmVW5xNlyOFc",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def extract_features(mail_dir):\n",
        "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)] #create list of \"files\" to each directory by joining directory path \"mail dir\" with file name \"fi\"\n",
        "  features_matrix = np.zeros((len(files),3000))\n",
        "  train_labels = np.zeros(len(files))\n",
        "  count = 1;\n",
        "  docID = 0;\n",
        "  for fil in files: #takes each file in \"files\" which contains the email files in directories\n",
        "    with open(fil) as fi: #ensures file will be closed automatically after it's done processing the file\n",
        "      for i, line in enumerate(fi):\n",
        "        if i ==2: #if the line numer is 2, code splits line into words \n",
        "          words = line.split() #the resulting words from above are stored in the \"words\" variable\n",
        "          for word in words:\n",
        "            wordID = 0\n",
        "            for i, d in enumerate(dictionary): #checks each word to see if it exists in the dictionary\n",
        "              if d[0] == word:\n",
        "                wordID = i\n",
        "                features_matrix[docID,wordID] = words.count(word) #updates the entry with the count of that word in the current email\n",
        "      train_labels[docID] = 0;\n",
        "      filepathTokens = fil.split('/') #splits the file path for the current file into tokens \n",
        "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
        "      if lastToken.startswith(\"spmsg\"): #identifies spam vs real mail based on naming \n",
        "        train_labels[docID] = 1;\n",
        "        count = count + 1\n",
        "      docID = docID + 1\n",
        "  return features_matrix, train_labels                "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section first uploads the test and train data from our google drive. Then this code enters our data into the Gaussian Naive Bayes Classifier model and predicting which category our emails fall into and print an accuracy score for the algorithm. "
      ],
      "metadata": {
        "id": "ZHa5uqEAI6rf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "id": "4p_DvtT7sOIr",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/BSAN6070/CA02/train-mails' #importing data from my google drive\n",
        "test_dir = '/content/drive/MyDrive/BSAN6070/CA02/test-mails' #importing data from my google \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "134lmhauyQxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3188c84c-c008-4a9f-b6af-7287e2448a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading and processing emails from TRAIN and TEST folders\n",
            "Training Model using Gaussian Naibe Bayes algorithm .....\n",
            "Training completed\n",
            "testing trained model to predict Test Data labels\n",
            "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
            "0.9615384615384616\n"
          ]
        }
      ],
      "source": [
        "dictionary=make_Dictionary(train_dir)\n",
        "\n",
        "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
        "features_matrix, labels = extract_features(train_dir) #processing and training of the train_dir folder\n",
        "test_features_matrix, test_labels = extract_features(test_dir) #tests the trained model using the test_dir\n",
        "\n",
        "model = GaussianNB() #imports the Gaussian Naive Bayes classifier to run the model\n",
        "\n",
        "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
        "model.fit(features_matrix, labels) #enters each function into the Gaussian Naive Bayes Classifier model \n",
        "print (\"Training completed\")\n",
        "print (\"testing trained model to predict Test Data labels\")\n",
        "predicted_labels = model.predict(test_features_matrix) #predicts which category to fall into\n",
        "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
        "print (accuracy_score(test_labels, predicted_labels)) #shows ending accuracy score of the algorithms ability to predict spam vs real emails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5_mPrvN586A"
      },
      "source": [
        "======================= END OF PROGRAM ========================="
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}